{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Goals: Rhyming\n",
    "In this Jupyter notebook, we train an unsupervised HMM on the given Shakespearean sonnets and generate a 14-line sonnet with appropriate rhyming line pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:15.972538Z",
     "start_time": "2020-03-17T10:00:15.154911Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "import string\n",
    "from HMM import unsupervised_HMM\n",
    "from HMM_helper import (\n",
    "    text_to_wordcloud,\n",
    "    states_to_wordclouds,\n",
    "    sample_sentence,\n",
    "    visualize_sparsities,\n",
    "    animate_emission\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:16.458944Z",
     "start_time": "2020-03-17T10:00:16.436969Z"
    }
   },
   "outputs": [],
   "source": [
    "original_text = open(os.path.join(os.getcwd(), 'data/shakespeare_no99_no126.txt')).read()\n",
    "original_text = \"\".join(filter(lambda x: not x.isdigit(), original_text)) \n",
    "original_text = original_text.lower().strip()\n",
    "original_text = re.sub(\"[.,?!\\\";:]\", \"\", original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:17.484329Z",
     "start_time": "2020-03-17T10:00:17.443015Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_text = re.sub(r'(\\n\\s*)+\\n', '\\n\\n', original_text)\n",
    "\n",
    "\n",
    "raw_lines = []\n",
    "\n",
    "for line in raw_text.split('\\n'):\n",
    "    if len(line) != 0:\n",
    "        temp = re.sub('^[^a-zA-Z]*|[^a-zA-Z]*$|','', line)\n",
    "        temp2 = re.sub(r'[\\(\\)]', '', temp)\n",
    "        temp3 = temp2.replace(\"' \",\" \").replace(\" '\",\" \")\n",
    "        raw_lines.append(temp3)\n",
    "        \n",
    "                     \n",
    "cleaned_raw_text = \"\\n\".join(raw_lines)\n",
    "\n",
    "sonnet_list = []\n",
    "sonnet = []\n",
    "for line in raw_lines:\n",
    "    line_split = line.split()\n",
    "    \n",
    "    sonnet.append(line_split)\n",
    "    if len(sonnet) == 14:\n",
    "        sonnet_list.append(sonnet)\n",
    "        sonnet = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:18.595596Z",
     "start_time": "2020-03-17T10:00:18.585156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create rhyming dictionary\n",
    "\n",
    "import copy\n",
    "\n",
    "rhyme_dict = dict()\n",
    "\n",
    "def update_rhyme_dict(w1,w2,my_dict):\n",
    "    if (w1 not in my_dict):\n",
    "        my_dict[word1] = set()\n",
    "\n",
    "    if (w2 not in my_dict):\n",
    "        my_dict[word2] = set()\n",
    "        \n",
    "    my_dict[w1].add(w2)\n",
    "    my_dict[w2].add(w1)\n",
    "    \n",
    "    for v1 in my_dict[w1]:\n",
    "        if (v1 != w2):\n",
    "            my_dict[w2].add(v1)\n",
    "    \n",
    "    for v2 in my_dict[w2]:\n",
    "        if (v2 != w1):\n",
    "            my_dict[w1].add(v2)\n",
    "\n",
    "for song in sonnet_list:\n",
    "\n",
    "    for (a,b) in [(0,2),(1,3), (4, 6), (5,7), (8, 10), (9,11), (12, 13)]:\n",
    "        word1, word2 = song[a][-1], song[b][-1]\n",
    "        \n",
    "        update_rhyme_dict(word1, word2, rhyme_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:19.758047Z",
     "start_time": "2020-03-17T10:00:19.743102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting syllable dictionary\n",
    "syllable_dict = {}\n",
    "file = open(os.path.join(os.getcwd(),\n",
    "                'data/Syllable_dictionary.txt')).read()\n",
    "lines = [line.split() for line in file.split('\\n') if line.split()]\n",
    "\n",
    "for line in lines:\n",
    "    real, end = [], []\n",
    "    for i in range(1, len(line)):\n",
    "        if line[i][0] == 'E':\n",
    "            end.append(int(line[i][1]))\n",
    "        else:\n",
    "            real.append(int(line[i][0]))\n",
    "    syllable_dict[line[0]] = [real[::-1], end[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:00:20.887557Z",
     "start_time": "2020-03-17T10:00:20.882341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Slight modification to HMM_helper parse_observations function\n",
    "\n",
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "        \n",
    "        ############################ \n",
    "        # CHANGE MADE: REVERSING LINES\n",
    "        line.reverse()\n",
    "        ############################\n",
    "        \n",
    "        for word in line:\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:36:50.257880Z",
     "start_time": "2020-03-17T10:00:23.048846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and save HMM model using pickle package\n",
    "obs, obs_map = parse_observations(cleaned_raw_text)  \n",
    "hmm = unsupervised_HMM(obs, 20, 100)\n",
    "\n",
    "pickle.dump(hmm, open( \"hmm_rhyme.model\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:37:15.257650Z",
     "start_time": "2020-03-17T10:37:15.244059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But can where very summer love increase\n",
      "Thy change is a conquest relief decease\n"
     ]
    }
   ],
   "source": [
    "hmm = pickle.load(open( \"hmm_rhyme.model\", \"rb\" ) )\n",
    "\n",
    "def invert_obs_map(o_map):\n",
    "    new_obs_map = dict()\n",
    "    \n",
    "    for key, val in o_map.items():\n",
    "        new_obs_map[val] = key\n",
    "    return new_obs_map\n",
    "\n",
    "def generate_sample_sentence(my_hmm, inv_obs_map, seed_word_idx, syl_dict, n_syl=10):\n",
    "    emission, states = my_hmm.generate_sonnet_rhyme_emission(n_syl, seed_word_idx, inv_obs_map, syl_dict)\n",
    "    \n",
    "    sentence = [inv_obs_map[elem] for elem in emission][::-1]\n",
    "    sentence[0] = sentence[0].capitalize()\n",
    "    \n",
    "    return \" \".join(sentence)\n",
    "\n",
    "i_obs_map = invert_obs_map(obs_map)\n",
    "\n",
    "print(generate_sample_sentence(hmm, i_obs_map, obs_map['increase'], syllable_dict))\n",
    "print(generate_sample_sentence(hmm, i_obs_map, obs_map['decease'], syllable_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:37:27.532692Z",
     "start_time": "2020-03-17T10:37:27.481769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even thus all those nature thy whom defy\n",
      "When the rich hardest space what but this lend\n",
      "Make the best to please and burn that thereby\n",
      "Beauteous got birds know the yet happier friend\n",
      "First music or you half former report\n",
      "He in executor swift character\n",
      "Shames now rage to thy self and to doth sport\n",
      "All lo upon thou am of register\n",
      "To been night transport plagues of thine broken\n",
      "To poesy with testy are in had\n",
      "They my own rotten love in so open\n",
      "Mine love hell add visage tomb lack me bad\n",
      "Not and thou thoughts not than my alchemy\n",
      "Thy and addeth another's majesty\n"
     ]
    }
   ],
   "source": [
    "# Generate 14-line Shakespearean sonnet with rhyming scheme\n",
    "def generate_shakespeare_sonnet(my_hmm, obs_map, rhyme_dict, syl_dict):\n",
    "    final_sonnet = []\n",
    "    \n",
    "    i_obs_map = invert_obs_map(obs_map)\n",
    "    \n",
    "    for _ in range(3):\n",
    "        word1 = np.random.choice(list(rhyme_dict.keys()))\n",
    "        word1_r = np.random.choice(list(rhyme_dict[word1]))\n",
    "        \n",
    "        word2 = np.random.choice(list(rhyme_dict.keys()))\n",
    "        word2_r = np.random.choice(list(rhyme_dict[word2]))\n",
    "        \n",
    "        temp1 = generate_sample_sentence(my_hmm, i_obs_map, obs_map[word1], syl_dict)\n",
    "        temp1_r = generate_sample_sentence(my_hmm, i_obs_map, obs_map[word1_r], syl_dict)\n",
    "        \n",
    "        temp2 = generate_sample_sentence(my_hmm, i_obs_map, obs_map[word2], syl_dict)\n",
    "        temp2_r = generate_sample_sentence(my_hmm, i_obs_map, obs_map[word2_r], syl_dict)\n",
    "        \n",
    "        final_sonnet.append(temp1)\n",
    "        final_sonnet.append(temp2)\n",
    "        final_sonnet.append(temp1_r)\n",
    "        final_sonnet.append(temp2_r)\n",
    "    \n",
    "    word_lst = np.random.choice(list(rhyme_dict.keys()))\n",
    "    word_lst_r = np.random.choice(list(rhyme_dict[word_lst]))\n",
    "    final_sonnet.append(generate_sample_sentence(my_hmm, i_obs_map, obs_map[word_lst], syl_dict))\n",
    "    final_sonnet.append(generate_sample_sentence(my_hmm, i_obs_map, obs_map[word_lst_r], syl_dict))\n",
    "    \n",
    "    return \"\\n\".join(final_sonnet)\n",
    "    \n",
    "print(generate_shakespeare_sonnet(hmm, obs_map, rhyme_dict, syllable_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
